{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "question2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNJYh0wO1N3RYTv7v5grtkC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jialan8020/Assign8/blob/master/question2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OssX6e4qxXdq",
        "colab_type": "code",
        "outputId": "79854a4e-6776-48f5-fe5f-4695d33c833d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "!pip install -u tensorflow_datasets\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "tfds.disable_progress_bar()\n",
        "\n",
        "# Helper libraries\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import logging\n",
        "logger = tf.get_logger()\n",
        "logger.setLevel(logging.ERROR)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Usage:   \n",
            "  pip3 install [options] <requirement specifier> [package-index-options] ...\n",
            "  pip3 install [options] -r <requirements file> [package-index-options] ...\n",
            "  pip3 install [options] [-e] <vcs project url> ...\n",
            "  pip3 install [options] [-e] <local project path> ...\n",
            "  pip3 install [options] <archive url/path> ...\n",
            "\n",
            "no such option: -u\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THXrx_yZyG8G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset, metadata = tfds.load(\"fashion_mnist\", as_supervised=True, with_info=True)\n",
        "train_dataset, test_dataset = dataset[\"train\"], dataset[\"test\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gkd3cZRkyyd7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The class names in order from 0 to 9\n",
        "class_names = [\"T-shirt/top\",\"Trouser\",\"Pullover\",\"Dress\",\"Coat\",\n",
        "               \"Sandal\",     \"Shirt\",  \"Sneaker\", \"Bag\",  \"Ankle boot\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-shVPnwsy9dh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize(images,labels):\n",
        "  images = tf.cast(images,tf.float32)\n",
        "  images /= 255\n",
        "  return images, labels\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMATeZs0znC0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = train_dataset.map(normalize)\n",
        "test_dataset = test_dataset.map(normalize)\n",
        "\n",
        "train_dataset = train_dataset.cache()\n",
        "test_dataset = test_dataset.cache()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGXNDxs90TDm",
        "colab_type": "text"
      },
      "source": [
        "Model 1: One hidden layer with 32 nodes; drop out 10% of the data for hidden layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEbBjf_xzt5G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_1 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28,1)),\n",
        "  tf.keras.layers.Dense(32, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.1),\n",
        "  tf.keras.layers.Dense(10)\n",
        "])\n",
        "model_1.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9I93aHd0vWv",
        "colab_type": "code",
        "outputId": "cb73697f-c7d4-408f-b1ea-29c960e764f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "model_1.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_1 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 32)                25120     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 25,450\n",
            "Trainable params: 25,450\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XISxCyn1sPD",
        "colab_type": "code",
        "outputId": "de2e1165-fa09-424a-b96a-df2b8318b874",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "num_train_examples = metadata.splits['train'].num_examples\n",
        "num_test_examples = metadata.splits['test'].num_examples\n",
        "print(\"Number of training examples: {}\".format(num_train_examples))\n",
        "print(\"Number of testing examples: {}\".format(num_test_examples))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 60000\n",
            "Number of testing examples: 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjRs-t8d1O00",
        "colab_type": "code",
        "outputId": "2cb08399-26ea-4d8b-f8f6-1db6c9b03ad6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "train_dataset = train_dataset.cache().repeat().shuffle(num_train_examples).batch(BATCH_SIZE)\n",
        "test_dataset = test_dataset.cache().batch(BATCH_SIZE)\n",
        "model_1.fit(train_dataset, epochs=5, steps_per_epoch=math.ceil(num_train_examples/BATCH_SIZE))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.5845 - accuracy: 0.7957\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4320 - accuracy: 0.8447\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3993 - accuracy: 0.8544\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3850 - accuracy: 0.8625\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3649 - accuracy: 0.8677\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7d3f5e6a20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBShPtPz39nH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f1d20f5d-ab45-41c4-f44c-aa9b5abf13e9"
      },
      "source": [
        "test_loss, test_accuracy = model_1.evaluate(test_dataset, steps=math.ceil(num_test_examples/BATCH_SIZE))\n",
        "print(\"Prediction on test dataset using model 1: {}\".format(test_accuracy))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 2s 8ms/step - loss: 0.3905 - accuracy: 0.8619\n",
            "Prediction on test dataset using model 1: 0.8618999719619751\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GxUauUN4eiC",
        "colab_type": "text"
      },
      "source": [
        "Model 2: Two hidden layer with 128 and 32 nodes; drop out 15% of the data for each hidden layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ckD9l4y4ckC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "a3287ead-9ff3-44a7-bdd0-19da8a459bfa"
      },
      "source": [
        "model_2 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28,1)),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.15),\n",
        "  tf.keras.layers.Dense(32, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.15),\n",
        "  tf.keras.layers.Dense(10)\n",
        "])\n",
        "model_2.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_2.fit(train_dataset, epochs=5, steps_per_epoch=math.ceil(num_train_examples/BATCH_SIZE))\n",
        "test_loss_2, test_accuracy_2 = model_2.evaluate(test_dataset, steps=math.ceil(num_test_examples/BATCH_SIZE))\n",
        "print(\"Prediction on test dataset using model 2: {}\".format(test_accuracy_2))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5878 - accuracy: 0.7921\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4246 - accuracy: 0.8482\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3891 - accuracy: 0.8594\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3668 - accuracy: 0.8662\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3489 - accuracy: 0.8734\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.3513 - accuracy: 0.8746\n",
            "Prediction on test dataset using model 2: 0.8745999932289124\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PsB5Woa5-oU",
        "colab_type": "text"
      },
      "source": [
        "Model 3: Two hidden layer with 128 and 64 nodes; drop out 20% of the data for each hidden layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LK5RYdiY5xps",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "a22a089e-2908-4030-e21a-3c71cbaa3ba7"
      },
      "source": [
        "model_3 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28,1)),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(64, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(10)\n",
        "])\n",
        "model_3.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_3.fit(train_dataset, epochs=5, steps_per_epoch=math.ceil(num_train_examples/BATCH_SIZE))\n",
        "test_loss_3, test_accuracy_3 = model_3.evaluate(test_dataset, steps=math.ceil(num_test_examples/BATCH_SIZE))\n",
        "print(\"Prediction on test dataset using model 2: {}\".format(test_accuracy_3))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5761 - accuracy: 0.7946\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4282 - accuracy: 0.8429\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3891 - accuracy: 0.8592\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.3654 - accuracy: 0.8659\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3495 - accuracy: 0.8725\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.3909 - accuracy: 0.8520\n",
            "Prediction on test dataset using model 2: 0.8519999980926514\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcnlIH056Swq",
        "colab_type": "text"
      },
      "source": [
        "Model 4: Three hidden layers with 128, 64 and 32 nodes; drop out 20% of the \n",
        "data for each hidden layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlRA4pfL6Yls",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "be49dcc7-8ed7-4b46-bb35-0e63d3e28777"
      },
      "source": [
        "model_4 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28,1)),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(64, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(32, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(10)\n",
        "])\n",
        "model_4.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_4.fit(train_dataset, epochs=5, steps_per_epoch=math.ceil(num_train_examples/BATCH_SIZE))\n",
        "test_loss_4, test_accuracy_4 = model_4.evaluate(test_dataset, steps=math.ceil(num_test_examples/BATCH_SIZE))\n",
        "print(\"Prediction on test dataset using model 2: {}\".format(test_accuracy_4))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.6738 - accuracy: 0.7611\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4783 - accuracy: 0.8332\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4264 - accuracy: 0.8490\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.4112 - accuracy: 0.8547\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3865 - accuracy: 0.8640\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.3766 - accuracy: 0.8666\n",
            "Prediction on test dataset using model 2: 0.866599977016449\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qMPvdST64ha",
        "colab_type": "text"
      },
      "source": [
        "Model 5: Three hidden layers with 128, 64 and 32 nodes; drop out 10% of the \n",
        "data for each hidden layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbYx1nfn6-2h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "2f43a0c9-c9cc-4c4c-bc45-704435684b2f"
      },
      "source": [
        "model_5 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28,1)),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.1),\n",
        "  tf.keras.layers.Dense(64, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.1),\n",
        "  tf.keras.layers.Dense(32, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.1),\n",
        "  tf.keras.layers.Dense(10)\n",
        "])\n",
        "model_5.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_5.fit(train_dataset, epochs=5, steps_per_epoch=math.ceil(num_train_examples/BATCH_SIZE))\n",
        "test_loss_5, test_accuracy_5 = model_5.evaluate(test_dataset, steps=math.ceil(num_test_examples/BATCH_SIZE))\n",
        "print(\"Prediction on test dataset using model 2: {}\".format(test_accuracy_5))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5968 - accuracy: 0.7865\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.4184 - accuracy: 0.8498\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.3825 - accuracy: 0.8615\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.3587 - accuracy: 0.8702\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.3440 - accuracy: 0.8732\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.3554 - accuracy: 0.8721\n",
            "Prediction on test dataset using model 2: 0.8720999956130981\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}